{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.base import TransformerMixin\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('/Users/anirudhsharma/FAI/ma_statewide_2020_04_01.csv', low_memory = False)\n",
    "print(data.head(10))\n",
    "\n",
    "# Checking all the nan values and handling them\n",
    "print(data.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "median1 = df['subject_age'].median()\n",
    "df['subject_age'].fillna(median1, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segregate the values based on the categories, remove the nulls and normalize the data column\n",
    "df['race'] = pd.Series(len(df['subject_race']), index=df.index)\n",
    "df['race'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To assign null values\n",
    "df.loc[(df['subject_race'] != 'hispanic') | \n",
    "           (df['subject_race'] != 'white') |\n",
    "           (df['subject_race'] != 'black') |\n",
    "           (df['subject_race'] != 'asian/pacific islander') |\n",
    "           (df['subject_race'] != 'other') |\n",
    "           (df['subject_race'].isnull() == True), 'race'] = np.nan\n",
    "\n",
    "#To assign the categorical values to the dataframe 'race'\n",
    "df.loc[(df['subject_race'] == 'hispanic') | \n",
    "           (df['subject_race'] == 'white') |\n",
    "           (df['subject_race'] == 'black') |\n",
    "           (df['subject_race'] == 'other') |\n",
    "           (df['subject_race'] == 'asian/pacific islander'), 'race'] = df['subject_race']\n",
    "\n",
    "race_copy = df['race'].copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values.\n",
    "df['race'].fillna(value = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain values for every race.Axis=0 for rows\n",
    "race_copy.dropna(axis = 0, inplace = True)\n",
    "sorted_race = race_copy.value_counts(normalize = True).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill one values for individual person with randomly picked from random choice.\n",
    "df['race'] = df['race'].apply(lambda x: np.random.choice([x for x in sorted_race.index],\n",
    "                                replace = True, p = sorted_race) if (x == 1) else x).astype(str)\n",
    "\n",
    "#Normalize=True prints the relative frequency of the values\n",
    "print(\"\\nFilled NaNs normalized:\\n\", df['race'].value_counts(normalize = True))\n",
    "\n",
    "df['subject_race'] = df['race']\n",
    "df['subject_race'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segregate the values based on the categories, remove the nulls and normalize the data column\n",
    "df['sex'] = pd.Series(len(df['subject_sex']), index = df.index)\n",
    "df['sex'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly stick sex to every user with NaN value.\n",
    "df.loc[(df['subject_sex'] != 'male') | \n",
    "           (df['subject_sex'] != 'female') |\n",
    "           (df['subject_sex'].isnull() == True), 'sex'] = np.nan\n",
    "df.loc[(df['subject_sex'] == 'male') | \n",
    "           (df['subject_sex'] == 'female'), 'sex'] = df['subject_sex']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy to calculate proportions.\n",
    "sex_copy = df['sex'].copy(deep = True)\n",
    "\n",
    "# Fill NaN values.\n",
    "df['sex'].fillna(value = 1, inplace = True)\n",
    "\n",
    "# Obtain values for every sex.\n",
    "sex_copy.dropna(axis = 0, inplace = True)\n",
    "sorted_sex = sex_copy.value_counts(normalize = True).sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill one values in suspector_sex_rand with randomly picked from random choice.\n",
    "df['sex'] = df['sex'].apply(lambda x: np.random.choice([x for x in sorted_sex.index],\n",
    "                                replace = True, p = sorted_sex) if (x == 1) else x).astype(str)\n",
    "print(\"Gender proportions after filled NaNs: \\n\", df['sex'].value_counts(normalize = True))\n",
    "\n",
    "df['subject_sex'] = df['sex']\n",
    "df['subject_sex'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segregate the values based on the categories, remove the nulls and normalize the data column\n",
    "df['outcome_v'] = pd.Series(len(df['outcome']), index = df.index)\n",
    "df['outcome_v'] = 0\n",
    "\n",
    "# Randomly stick sex to every user with NaN value.\n",
    "df.loc[(df['outcome'] != 'citation') | \n",
    "           (df['outcome'] != 'warning') |\n",
    "           (df['outcome'] != 'arrest') |\n",
    "           (df['outcome'].isnull() == True), 'outcome_v'] = np.nan\n",
    "df.loc[(df['outcome'] != 'citation') | \n",
    "           (df['outcome'] != 'warning') |\n",
    "           (df['outcome'] != 'arrest'), 'outcome_v'] = df['outcome']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy to calculate proportions.\n",
    "outcome_copy = df['outcome_v'].copy(deep = True)\n",
    "\n",
    "# Fill NaN values.\n",
    "df['outcome_v'].fillna(value = 1, inplace = True)\n",
    "\n",
    "outcome_copy.dropna(axis = 0, inplace = True)\n",
    "sorted_outcome = outcome_copy.value_counts(normalize = True).sort_index()\n",
    "\n",
    "# Fill one values in suspector_sex_rand with randomly picked from random choice.\n",
    "df['outcome_v'] = df['outcome_v'].apply(lambda x: np.random.choice([x for x in sorted_outcome.index],\n",
    "                                replace = True, p = sorted_outcome) if (x == 1) else x).astype(str)\n",
    "print(\"Outcome proportions after filled NaNs: \\n\", df['outcome_v'].value_counts(normalize = True))\n",
    "\n",
    "df['outcome'] = df['outcome_v']\n",
    "df['outcome'].value_counts()\n",
    "\n",
    "#Segregate the values based on the categories, remove the nulls and normalize the data column\n",
    "df['vehicle'] = pd.Series(len(df['vehicle_type']), index = df.index)\n",
    "df['vehicle'] = 0\n",
    "\n",
    "df.loc[(df['vehicle_type'] != 'Commerical') | \n",
    "           (df['vehicle_type'] != 'Passenger') |\n",
    "           (df['vehicle_type'] != 'Motorcycle') |\n",
    "           (df['vehicle_type'] != 'Taxi/Livery') |\n",
    "           (df['vehicle_type'] != 'Trailer') |\n",
    "           (df['vehicle_type'].isnull() == True), 'vehicle'] = np.nan\n",
    "df.loc[(df['vehicle_type'] != 'Commerical') | \n",
    "           (df['vehicle_type'] != 'Passenger') |\n",
    "           (df['vehicle_type'] != 'Motorcycle') |\n",
    "           (df['vehicle_type'] != 'Taxi/Livery') |\n",
    "           (df['vehicle_type'] != 'Trailer'), 'vehicle'] = df['vehicle_type']\n",
    "\n",
    "\n",
    "# Create a copy to calculate proportions.\n",
    "outcome_copy = df['vehicle'].copy(deep = True)\n",
    "\n",
    "# Fill NaN values.\n",
    "df['vehicle'].fillna(value = 1, inplace = True)\n",
    "\n",
    "outcome_copy.dropna(axis = 0, inplace = True)\n",
    "sorted_outcome = outcome_copy.value_counts(normalize = True).sort_index()\n",
    "\n",
    "# Fill one values in suspector_sex_rand with randomly picked from random choice.\n",
    "df['vehicle'] = df['vehicle'].apply(lambda x: np.random.choice([x for x in sorted_outcome.index],\n",
    "                                replace = True, p = sorted_outcome) if (x == 1) else x).astype(str)\n",
    "print(\"Vehicle Type proportions after filled NaNs: \\n\", df['vehicle'].value_counts(normalize = True))\n",
    "\n",
    "df['vehicle_type'] = df['vehicle']\n",
    "df['vehicle_type'].value_counts()\n",
    "\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(df['arrest_made'].unique())\n",
    "print(df['citation_issued'].unique())\n",
    "print(df['warning_issued'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the date into segments for day , date and year \n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['year'] = df['date'].dt.year\n",
    "df['month'] = df['date'].dt.month\n",
    "df['day'] = df['date'].dt.day\n",
    "\n",
    "print(df['month'].head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "\n",
    "        Columns of other types are imputed with mean of column.\n",
    "\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(df)\n",
    "new_data = DataFrameImputer().fit_transform(X)\n",
    "\n",
    "print('before...')\n",
    "print(X)\n",
    "print('after...')\n",
    "print(new_data)\n",
    "\n",
    "print(new_data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Using linear regression, we want to predict the age of the person who has been stopped\"\"\"\n",
    "\n",
    "#Let us first define the categorical variables\n",
    "\n",
    "not_categorical_vars = ['raw_row_number',\n",
    "                        'date',\n",
    "                        'subject_age']\n",
    "\n",
    "for categorical in list(new_data.columns):\n",
    "    if categorical not in not_categorical_vars:\n",
    "        new_data[categorical] = new_data[categorical].astype('category')\n",
    "\n",
    "print(new_data.info())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let us now encode the data. As we have a lot of categories among the variables \n",
    "\n",
    "categorical_vars = ['subject_sex',\n",
    "                    'subject_race',\n",
    "                    'type',\n",
    "                    'arrest_made',\n",
    "                    'citation_issued',\n",
    "                    'outcome',\n",
    "                    'contraband_found',\n",
    "                    'contraband_drugs',\n",
    "                    'warning_issued',\n",
    "                    'contraband_weapons',\n",
    "                    'contraband_alcohol',\n",
    "                    'contraband_other',\n",
    "                    'frisk_performed',\n",
    "                    'search_conducted',\n",
    "                    'search_basis',\n",
    "                    'reason_for_stop',\n",
    "                    'vehicle_type',\n",
    "                    'vehicle_registration_state',\n",
    "                    'raw_Race',\n",
    "                    'race',\n",
    "                    'sex',\n",
    "                    'outcome_v',\n",
    "                    'vehicle']\n",
    "\n",
    "\n",
    "def make_dummies(dataset, dummy_list):\n",
    "    for i in dummy_list:\n",
    "        dummy = pd.get_dummies(dataset[i], prefix= i, dummy_na= False)\n",
    "        dataset = dataset.drop(i,1)\n",
    "        dataset = pd.concat([dataset,dummy], axis = 1)\n",
    "    return dataset\n",
    "\n",
    "dummy_data =make_dummies(new_data,categorical_vars)\n",
    "\n",
    "print(dummy_data.head)\n",
    "print(dummy_data['subject_age'].head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple linear regression using sklearn to predict the age of the person stopped \n",
    "\"\"\" Define dependent and independent variables\"\"\"\n",
    "\n",
    "X = dummy_data.drop(['raw_row_number','subject_age','date','location','county_name'], axis= 1)\n",
    "#X = X.values.reshape(-1,1)\n",
    "\n",
    "Y = dummy_data['subject_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" First we need to split the dataset in to test and train and dependent and independent variables\"\"\"\n",
    "print(\"Before splitting\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train , y_test = train_test_split(X,Y, test_size= 0.25, random_state = 12345)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "\n",
    "print(\"Training start\")\n",
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "print(\"Trained\")\n",
    "\n",
    "lm_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix, mean_squared_error, mean_absolute_error, explained_variance_score\n",
    "\n",
    "mse = mean_squared_error(y_test, lm_pred)\n",
    "mae = mean_absolute_error(y_test, lm_pred)\n",
    "evs = explained_variance_score(y_test, lm_pred)\n",
    "\n",
    "metrics = {\"mse\":mse,\n",
    "           \"mae\":mae,\n",
    "           \"evs\":evs\n",
    "}\n",
    "\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_train_new = sm.add_constant(X_train)\n",
    "lm_1 = sm.OLS(y_train, X_train).fit()\n",
    "print(lm_1.summary())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Simple linear regression from scratch to predict the age of the person stopped by the police \n",
    "\n",
    "\n",
    "class lin_reg():\n",
    "    \"\"\"\n",
    "    predicts the age of person stopped taking input of \n",
    "    the history of the stops\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, learning_rate = 0.001, epochs = 100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.epochs = epochs\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "\n",
    "    def fit(self,X,y):\n",
    "        \"\"\" Takes in the training samples and labels\"\"\"\n",
    "        # initialize the parameters \n",
    "        number_samples , number_features = X.shape\n",
    "        self.weights = np.zeros(number_features)\n",
    "        self.bias = 0\n",
    "        \n",
    "        for _ in range(self.epochs):\n",
    "            predicted_y = np.dot(X, self.weights) + self.bias\n",
    "            #derivative of weight\n",
    "            dw =(1/number_samples) * np.dot(X.T , (predicted_y - y))\n",
    "            # Derivative of bias \n",
    "            db = (1/ number_samples) * np.sum(predicted_y - y)\n",
    "\n",
    "            self.weights -= self.learning_rate * dw\n",
    "            self.bias -= self.learning_rate * db\n",
    "    \n",
    "\n",
    "    def pred(self, X):\n",
    "        predicted_y = np.dot(X, self.weights) + self.bias\n",
    "        return predicted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = lin_reg()\n",
    "regressor.fit(X_train, y_train)\n",
    "predicted_vals = regressor.pred(X_test)\n",
    "\n",
    "def mean_sq(y_true, y_predicted):\n",
    "    np.mean((y_true - y_predicted)** 2)\n",
    "\n",
    "mse_value = mean_sq(y_test,predicted_vals)\n",
    "print(mse_value)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Ridge and Lasso regression\"\"\"\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "# instantiate ridge regression method\n",
    "\n",
    "ridge_r = Ridge(alpha= 0.01)\n",
    "ridge_r.fit(X_train,y_train)\n",
    "train_pred_ridge = ridge_r.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,train_pred_ridge)))\n",
    "#print(r2_score(y_test, train_pred_ridge))\n",
    "\n",
    "# Instantiate lasso regressor method \n",
    "lasso_r = Lasso(alpha=0.01)\n",
    "lasso_r.fit(X_train, y_train) \n",
    "pred_train_lasso= lasso_r.predict(X_train)\n",
    "print(np.sqrt(mean_squared_error(y_train,pred_train_lasso)))\n",
    "#print(r2_score(y_train, pred_train_lasso))\n",
    "\n",
    "pred_test_lasso= lasso_r.predict(X_test)\n",
    "print(np.sqrt(mean_squared_error(y_test,pred_test_lasso))) \n",
    "#print(r2_score(y_test, pred_test_lasso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}